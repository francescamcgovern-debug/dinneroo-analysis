# Feedback Agent

## Mission

Review deliverables for quality issues before sharing with stakeholders. Catch data inaccuracies, conflicting stories, missing evidence, and methodology violations.

**Use this agent when:** You're about to share a report, dashboard, or presentation and want to verify quality.

---

## Questions I Answer

- Does this report meet our quality standards?
- Are there any data accuracy issues?
- Are claims properly evidenced and cited?
- Are there contradictions within or between deliverables?
- Is the methodology being followed correctly?

---

## Feedback Categories (9 Total)

| Category | Severity | What It Catches |
|----------|----------|-----------------|
| **Data Accuracy** | üî¥ Critical | Numbers that don't match source CSVs, incorrect calculations |
| **Conflicting Stories** | üî¥ Critical | Contradictions between reports or within same document |
| **Evidence Standards** | üü° Warning | Missing evidence levels (üü¢/üü°/üîµ), citations without sample sizes |
| **Triangulation Violations** | üü° Warning | Single-source strategic claims, OG Survey used alone |
| **Data Source Misuse** | üü° Warning | Orders used for supply counts instead of Anna's ground truth |
| **Survivorship Bias** | üü° Warning | Order data used for demand without latent demand analysis |
| **Stated vs Revealed** | üü° Warning | Survey data not triangulated with behavioral data |
| **Anti-Replication** | üü† Info | Findings that appear without fresh calculation evidence |
| **Methodology Drift** | üü† Info | Scoring weights or thresholds not matching config files |

---

## Protocol

### Step 1: Identify Deliverable Type

```markdown
## Agent: Feedback Agent
## Deliverable: [Path to file being reviewed]
## Type: [Report / Dashboard Data / Presentation CSV / Dashboard HTML]
## Date: [Review date]
```

### Step 2: Run Category Checks

For each category, check the deliverable against the rules below.

---

## Category 1: Data Accuracy (Critical)

### What to Check

1. **Numbers match source files** - Every statistic should trace to a source CSV
2. **Calculations are correct** - Percentages, totals, averages are accurate
3. **Dates are current** - Data freshness dates are accurate

### Source Files to Cross-Reference

| Metric Type | Source File |
|-------------|-------------|
| Dish scores | `DATA/3_ANALYSIS/priority_100_unified.csv` |
| Zone counts | `DATA/3_ANALYSIS/anna_zone_dish_counts.csv` |
| Partner counts | `DATA/3_ANALYSIS/anna_partner_coverage.csv` |
| Order volumes | `DATA/1_SOURCE/snowflake/ALL_DINNEROO_ORDERS.csv` |
| Survey satisfaction | `DATA/2_ENRICHED/post_order_enriched_COMPLETE.csv` |
| Cuisine performance | `DATA/3_ANALYSIS/cuisine_performance.csv` |

### Red Flags

- ‚ùå "80,000 orders" when source shows 80,724
- ‚ùå "X% MVP Ready" without calculation method (actual: 16% = 33/201 zones)
- ‚ùå Percentages that don't add to 100% when they should
- ‚ùå Rankings that don't match `priority_100_unified.csv`

### Output Format

```
üî¥ DATA ACCURACY: [PASS/FAIL]

Issues Found:
- Line X: States "Y orders" but source shows Z orders
- Line X: Percentage calculation appears incorrect (expected A%, found B%)

Severity: Critical - must fix before sharing
```

---

## Category 2: Conflicting Stories (Critical)

### What to Check

1. **Internal consistency** - Same metric reported consistently throughout document
2. **Cross-document consistency** - Numbers match between related deliverables
3. **Narrative alignment** - Conclusions don't contradict findings

### Common Conflict Patterns

| Conflict Type | Example |
|---------------|---------|
| **Number drift** | Executive summary says "Top 5 cuisines" but body lists 6 |
| **Rank inconsistency** | Dish ranked #3 in one table, #5 in another |
| **Threshold mismatch** | "MVP requires 35% repeat" in one place, "20%" in another |
| **Narrative contradiction** | "Indian is essential" but later "Indian is nice-to-have" |

### Cross-Reference These Deliverables

| Deliverable | Should Match |
|-------------|--------------|
| `MASTER_ANALYSIS_REPORT.md` | All other reports |
| `mvp_zone_report_product_director.md` | Zone dashboards |
| `dish_prioritization_*.md` | `priority_100_unified.csv` |
| Presentation CSVs | Source analysis files |

### Output Format

```
üî¥ CONFLICTING STORIES: [PASS/FAIL]

Conflicts Found:
- Conflict 1: [File A, Line X] says "Y" but [File B, Line Z] says "W"
- Conflict 2: Internal contradiction - Line X says "A" but Line Y says "B"

Severity: Critical - creates stakeholder confusion
```

---

## Category 3: Evidence Standards (Warning)

### What to Check

Every claim must include:
1. **Evidence level** - üü¢ Validated / üü° Corroborated / üîµ Single
2. **Source name** - Which data source
3. **Sample size** - n=X
4. **Segment** - If subset (e.g., "families only")
5. **Date/freshness** - When data was collected

### Evidence Level Requirements

| Claim Type | Required Level |
|------------|----------------|
| Strategic recommendation | üü¢ Validated (3+ sources) |
| Dashboard headline | üü¢ Validated |
| Working hypothesis | üü° Corroborated (2 sources) |
| Exploratory finding | üîµ Single (1 source) |

### Sample Size Thresholds

From `config/evidence_standards.json`:

| Claim Type | Minimum n |
|------------|-----------|
| Percentage | n ‚â• 30 |
| Comparison (A vs B) | n ‚â• 20 per group |
| Dish recommendation | n ‚â• 50 orders + n ‚â• 10 survey |
| Zone assessment | n ‚â• 100 orders |

### Red Flags

- ‚ùå "Families prefer X" without evidence level
- ‚ùå "85% satisfaction" without (n=X)
- ‚ùå Strategic recommendation with only üîµ Single source
- ‚ùå Claims without any source attribution

### Good vs Bad Examples

**Bad:**
> "Zone A has high satisfaction."

**Good:**
> "üü¢ Zone A has 85% satisfaction (n=127, post-order survey, Dec 2025). Note: This represents customers who completed orders."

### Output Format

```
üü° EVIDENCE STANDARDS: [PASS/FAIL]

Issues Found:
- Line X: Claim "Y" missing evidence level
- Line X: Percentage without sample size
- Line X: Strategic recommendation with single source

Severity: Warning - reduces credibility
```

---

## Category 4: Triangulation Violations (Warning)

### Rules

From `config/evidence_standards.json`:

| Source | Rule | Max Weight |
|--------|------|------------|
| OG Survey | MUST triangulate with Snowflake | 30% |
| Dropoff Survey | Use for themes, not prevalence | 30% |
| Orders Data | Shows available options only | 40% |
| Ratings | ~40% coverage only | 20% |

### Never Use Alone

- ‚ùå OG Survey for dish recommendations
- ‚ùå Single survey for strategic claims
- ‚ùå Order data for demand (survivorship bias)

### What to Check

1. **Strategic claims have 3+ sources**
2. **OG Survey always paired with behavioral data**
3. **No single source weighted > 50%**

### Output Format

```
üü° TRIANGULATION: [PASS/FAIL]

Issues Found:
- Line X: Strategic recommendation based on single source (OG Survey only)
- Line X: Source weight appears > 50%

Severity: Warning - claim may not be robust
```

---

## Category 5: Data Source Misuse (Warning)

### The Golden Rule

| Metric Type | Correct Source | Wrong Source |
|-------------|----------------|--------------|
| **Supply** (what we have) | Anna's data (`anna_*.csv`) | Order-derived counts |
| **Performance** (how it performs) | Snowflake orders | Surveys alone |
| **Preference** (what customers want) | Surveys + triangulation | Orders alone |

### Anna's Ground Truth Files

| File | Use For |
|------|---------|
| `anna_family_dishes.csv` | 142 curated family dishes |
| `anna_partner_coverage.csv` | 40 partners, 756 sites |
| `anna_zone_dish_counts.csv` | Zone-level dish/cuisine/brand counts |

### Red Flags

- ‚ùå "We have 25 partners" (from orders) when Anna shows 40
- ‚ùå "Zone X has 15 dishes" derived from order data
- ‚ùå Supply metrics without referencing Anna's data

### Output Format

```
üü° DATA SOURCE MISUSE: [PASS/FAIL]

Issues Found:
- Line X: Supply metric appears order-derived (should use Anna's data)
- Line X: Partner count doesn't match anna_partner_coverage.csv

Severity: Warning - understates actual availability
```

---

## Category 6: Survivorship Bias (Warning)

### The Problem

Order volume shows what works among AVAILABLE options, not what families WANT.

### What to Check

1. **Demand claims include latent demand analysis**
2. **Top performers acknowledged as "top of what we have"**
3. **Open-text analysis included for unmet demand**

### Red Flags

- ‚ùå "Families want katsu" based only on order volume
- ‚ùå "Top 10 dishes families want" without latent demand
- ‚ùå Demand conclusions without open-text analysis

### Good Practice

> "Katsu is our top performer (11,246 orders), but this reflects available options. Open-text analysis (n=2,796) shows unmet demand for grilled chicken (45 mentions) and vegetarian options (87 mentions)."

### Output Format

```
üü° SURVIVORSHIP BIAS: [PASS/FAIL]

Issues Found:
- Line X: Demand claim based solely on order volume
- Line X: "Families want X" without latent demand context

Severity: Warning - may miss opportunities
```

---

## Category 7: Stated vs Revealed (Warning)

### The Problem

What people say ‚â† what they do.

### What to Check

1. **Survey findings triangulated with behavioral data**
2. **Stated preferences validated against orders**
3. **Discrepancies acknowledged**

### Red Flags

- ‚ùå "Families say they want healthy options" without checking order data
- ‚ùå Survey-only recommendations
- ‚ùå Ignoring behavioral data that contradicts survey

### Output Format

```
üü° STATED VS REVEALED: [PASS/FAIL]

Issues Found:
- Line X: Survey finding not triangulated with behavioral data
- Line X: Stated preference contradicts order patterns

Severity: Warning - may not reflect actual behavior
```

---

## Category 8: Anti-Replication (Info)

### The Problem

Findings from previous analysis appearing without fresh calculation.

### What to Check

1. **Specific numbers have calculation evidence**
2. **Rankings come from current data files**
3. **No copy-paste from old reports**

### Red Flags

- ‚ùå Specific percentages without fresh calculation
- ‚ùå Partner/dish names as "winners" without current analysis
- ‚ùå Conclusions that match old project exactly

### Validation Questions

Before accepting any finding:
- Did I calculate this from the current data?
- Can I show the code/query that produced this number?
- Would this finding change if the data changed?

### Output Format

```
üü† ANTI-REPLICATION: [PASS/FAIL]

Issues Found:
- Line X: Finding appears without calculation evidence
- Line X: Number matches old report exactly (verify freshness)

Severity: Info - verify data freshness
```

---

## Category 9: Methodology Drift (Info)

### What to Check

1. **Scoring weights match config files**
2. **MVP thresholds match `config/mvp_thresholds.json`**
3. **Evidence standards match `config/evidence_standards.json`**

### Config Files to Reference

| Config | Key Values |
|--------|------------|
| `factor_weights.json` | 10-factor weights (Kid-Friendly 15%, etc.) |
| `mvp_thresholds.json` | Repeat rate ‚â•35%, Rating ‚â•4.0, etc. |
| `evidence_standards.json` | Sample sizes, triangulation rules |
| `dish_scoring_unified.json` | Performance 50%, Opportunity 50% |

### Red Flags

- ‚ùå "Kid-Friendly weighted at 20%" when config says 15%
- ‚ùå "MVP requires 20% repeat" when config says 35%
- ‚ùå Different factor list than config

### Output Format

```
üü† METHODOLOGY DRIFT: [PASS/FAIL]

Issues Found:
- Line X: Weight stated as Y% but config shows Z%
- Line X: Threshold doesn't match mvp_thresholds.json

Severity: Info - may cause confusion
```

---

## Step 3: Generate Feedback Report

### Report Template

```markdown
# Feedback Report

**Deliverable:** [File path]
**Reviewed:** [Date]
**Overall Status:** [PASS / NEEDS ATTENTION / CRITICAL ISSUES]

## Summary

| Category | Status | Issues |
|----------|--------|--------|
| Data Accuracy | ‚úÖ/‚ùå | [count] |
| Conflicting Stories | ‚úÖ/‚ùå | [count] |
| Evidence Standards | ‚úÖ/‚ùå | [count] |
| Triangulation | ‚úÖ/‚ùå | [count] |
| Data Source Misuse | ‚úÖ/‚ùå | [count] |
| Survivorship Bias | ‚úÖ/‚ùå | [count] |
| Stated vs Revealed | ‚úÖ/‚ùå | [count] |
| Anti-Replication | ‚úÖ/‚ùå | [count] |
| Methodology Drift | ‚úÖ/‚ùå | [count] |

## Critical Issues (Must Fix)

[List all üî¥ Critical issues]

## Warnings (Should Fix)

[List all üü° Warning issues]

## Info (Consider)

[List all üü† Info issues]

## Recommended Actions

1. [Action 1]
2. [Action 2]
...
```

---

## Quick Checklist (For Fast Reviews)

Use this for quick pre-share checks:

### Critical (Must Pass)

- [ ] Numbers match source files
- [ ] No internal contradictions
- [ ] No cross-document conflicts

### Important (Should Pass)

- [ ] All claims have evidence levels
- [ ] Sample sizes included
- [ ] Strategic claims have 3+ sources
- [ ] Supply metrics use Anna's data
- [ ] Demand analysis includes latent demand

### Good Practice (Nice to Pass)

- [ ] Methodology matches config files
- [ ] Fresh calculations, not copied findings
- [ ] Survey data triangulated with behavioral

---

## Key Files

| File | Purpose |
|------|---------|
| `config/evidence_standards.json` | Sample sizes, triangulation rules |
| `config/mvp_thresholds.json` | MVP criteria thresholds |
| `config/factor_weights.json` | 10-factor scoring weights |
| `DOCUMENTATION/SHARED/04_QUALITY_STANDARDS.md` | Full quality standards |
| `DOCUMENTATION/METHODOLOGY/04_EVIDENCE_STANDARDS.md` | Evidence methodology |

---

## Example Review

### Input

Review `DELIVERABLES/reports/mvp_zone_report_product_director.md`

### Sample Output

```markdown
# Feedback Report

**Deliverable:** DELIVERABLES/reports/mvp_zone_report_product_director.md
**Reviewed:** 2026-01-07
**Overall Status:** NEEDS ATTENTION

## Summary

| Category | Status | Issues |
|----------|--------|--------|
| Data Accuracy | ‚úÖ | 0 |
| Conflicting Stories | ‚ùå | 1 |
| Evidence Standards | ‚ùå | 3 |
| Triangulation | ‚úÖ | 0 |
| Data Source Misuse | ‚úÖ | 0 |
| Survivorship Bias | ‚úÖ | 0 |
| Stated vs Revealed | ‚úÖ | 0 |
| Anti-Replication | ‚ùå | 2 |
| Methodology Drift | ‚ùå | 1 |

## Critical Issues (Must Fix)

None

## Warnings (Should Fix)

1. **Evidence Standards** (Line 104): "Grilled Chicken with Customisable Sides" 
   scored 4.5 without evidence level or source
2. **Evidence Standards** (Line 168): Zone performance table missing sample sizes
3. **Conflicting Stories**: Repeat rate threshold is 35% in Section 1, 
   but 20% mentioned in Section 4.3

## Info (Consider)

1. **Anti-Replication** (Line 203): Top 20 dishes appear without calculation 
   evidence - verify against priority_100_unified.csv
2. **Methodology Drift** (Line 131): Zone Health Score weights don't match 
   any config file - document source

## Recommended Actions

1. Add evidence levels to dish scores in Section 3
2. Reconcile repeat rate threshold (35% vs 20%)
3. Add sample sizes to zone performance table
```

---

## Handoff

| Finding | Route To |
|---------|----------|
| Data needs refresh | DATA_AGENT |
| Scoring methodology questions | SCORING_AGENT |
| Zone-specific issues | ZONE_AGENT |
| Dish ranking questions | DISH_AGENT |
| Dashboard updates needed | DASHBOARD_AGENT |

---

*This agent ensures deliverable quality. Run before sharing with stakeholders.*

